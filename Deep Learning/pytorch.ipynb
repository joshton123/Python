{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da4d7c27-38a8-4497-b232-b1fb2615c425",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://download.pytorch.org/whl/cpu\n",
      "Requirement already satisfied: torch==2.5.0 in c:\\users\\dell\\appdata\\roaming\\python\\python312\\site-packages (2.5.0+cpu)\n",
      "Requirement already satisfied: torchvision==0.20.0 in c:\\users\\dell\\appdata\\roaming\\python\\python312\\site-packages (0.20.0+cpu)\n",
      "Requirement already satisfied: torchaudio==2.5.0 in c:\\users\\dell\\appdata\\roaming\\python\\python312\\site-packages (2.5.0+cpu)\n",
      "Requirement already satisfied: filelock in c:\\users\\dell\\appdata\\roaming\\python\\python312\\site-packages (from torch==2.5.0) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\dell\\appdata\\roaming\\python\\python312\\site-packages (from torch==2.5.0) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\dell\\appdata\\roaming\\python\\python312\\site-packages (from torch==2.5.0) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\dell\\appdata\\roaming\\python\\python312\\site-packages (from torch==2.5.0) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\dell\\appdata\\roaming\\python\\python312\\site-packages (from torch==2.5.0) (2024.2.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\dell\\appdata\\roaming\\python\\python312\\site-packages (from torch==2.5.0) (70.3.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\dell\\appdata\\roaming\\python\\python312\\site-packages (from torch==2.5.0) (1.13.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\dell\\appdata\\roaming\\python\\python312\\site-packages (from torchvision==0.20.0) (1.26.3)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\dell\\appdata\\roaming\\python\\python312\\site-packages (from torchvision==0.20.0) (10.2.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\dell\\appdata\\roaming\\python\\python312\\site-packages (from sympy==1.13.1->torch==2.5.0) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\dell\\appdata\\roaming\\python\\python312\\site-packages (from jinja2->torch==2.5.0) (2.1.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch==2.5.0 torchvision==0.20.0 torchaudio==2.5.0 --index-url https://download.pytorch.org/whl/cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3d10c36-3afe-4d44-a1b8-e41d6ce9a23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fabba131-d87f-41fd-8d98-d5f17cb6cfc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number\n",
    "t1 = torch.tensor(4.)\n",
    "t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0628ecdf-0175-4701-80ff-c366c447986a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d805966-be2a-456d-8005-ebd128f49f6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3., 4.])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vector\n",
    "t2 = torch.tensor([1., 2, 3, 4])\n",
    "t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "69443d44-d913-4ac6-9d04-d44fed40a293",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 5.,  6.],\n",
       "        [ 7.,  8.],\n",
       "        [ 9., 10.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Matrix\n",
    "t3 = torch.tensor([[5., 6],\n",
    "                   [7, 8],\n",
    "                   [9, 10]])\n",
    "t3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53821552-dc97-47fb-a7a9-26e306492fe8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[11., 12., 13.],\n",
       "         [13., 14., 15.]],\n",
       "\n",
       "        [[15., 16., 17.],\n",
       "         [17., 18., 19.]]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3-dimensional array\n",
    "t4 = torch.tensor([\n",
    "    [[11, 12, 13],\n",
    "     [13, 14, 15]],\n",
    "    [[15, 16, 17],\n",
    "     [17, 18, 19.]]])\n",
    "t4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3fa390b1-ec94-47c3-a2a9-b254e94523c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(3.), tensor(4., requires_grad=True), tensor(5., requires_grad=True))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create tensors.\n",
    "x = torch.tensor(3.)\n",
    "w = torch.tensor(4., requires_grad=True)\n",
    "b = torch.tensor(5., requires_grad=True)\n",
    "x, w, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "33468229-e2da-4c74-8ce1-5293e1e909ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(17., grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Arithmetic operations\n",
    "y = w * x + b\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3768f433-3823-4aef-8998-ac9e306f29fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(17., grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Arithmetic operations\n",
    "y = w * x + b\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b3697d0d-8ccf-4a0f-b8ae-7d1f06257917",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute derivatives\n",
    "y.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1432e57c-c14c-410a-9c91-8ca8a3b2b93e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dy/dx: None\n",
      "dy/dw: tensor(3.)\n",
      "dy/db: tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "# Display gradients\n",
    "print('dy/dx:', x.grad)\n",
    "print('dy/dw:', w.grad)\n",
    "print('dy/db:', b.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e800865f-95f2-4b7b-8278-da7523229b0d",
   "metadata": {},
   "source": [
    "## Tensor functions\n",
    "\n",
    "Apart from arithmetic operations, the `torch` module also contains many functions for creating and manipulating tensors. Let's look at some examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d096671a-96f6-42fa-8b41-f296aba8e701",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[42, 42],\n",
       "        [42, 42],\n",
       "        [42, 42]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor with a fixed value for every element\n",
    "t6 = torch.full((3, 2), 42)\n",
    "t6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c8c4f1e0-3408-4eec-b47d-7ca82e8296d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 5.,  6.],\n",
       "        [ 7.,  8.],\n",
       "        [ 9., 10.],\n",
       "        [42., 42.],\n",
       "        [42., 42.],\n",
       "        [42., 42.]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenate two tensors with compatible shapes\n",
    "t7 = torch.cat((t3, t6))\n",
    "t7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "949b9085-0b47-4cd8-92c4-563a35b3e7e2",
   "metadata": {},
   "source": [
    "## Interoperability with Numpy\n",
    "\n",
    "[Numpy](http://www.numpy.org/) is a popular open-source library used for mathematical and scientific computing in Python. It enables efficient operations on large multi-dimensional arrays and has a vast ecosystem of supporting libraries, including:\n",
    "\n",
    "* [Pandas](https://pandas.pydata.org/) for file I/O and data analysis\n",
    "* [Matplotlib](https://matplotlib.org/) for plotting and visualization\n",
    "* [OpenCV](https://opencv.org/) for image and video processing\n",
    "\n",
    "\n",
    "Instead of reinventing the wheel, PyTorch interoperates well with Numpy to leverage its existing ecosystem of tools and libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "99e35e9d-8058-4419-9e6d-c48537a810ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 2.],\n",
       "       [3., 4.]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "x = np.array([[1, 2], [3, 4.]])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "428d47ea-59bb-4b75-96af-60406a3f0ee4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2.],\n",
       "        [3., 4.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the numpy array to a torch tensor.\n",
    "y = torch.from_numpy(x)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "92fe41d3-a69c-4a2b-9c18-f10634110dee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dtype('float64'), torch.float64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.dtype, y.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "83d6aaf9-d90d-40be-b287-d9bb720c239f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 2.],\n",
       "       [3., 4.]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert a torch tensor to a numpy array\n",
    "z = y.numpy()\n",
    "z"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb54983b-7129-47ac-b46e-7795fb6e9875",
   "metadata": {},
   "source": [
    "## Linear-regression from scrach using pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "30784a8f-011d-4ffd-9f06-6b8d331f878a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "75b02f00-a272-463f-ab46-ae686ca7400e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#making training data\n",
    "# Input (temp, rainfall, humidity)\n",
    "inputs = np.array([[73, 67, 43],\n",
    "                   [91, 88, 64],\n",
    "                   [87, 134, 58],\n",
    "                   [102, 43, 37],\n",
    "                   [69, 96, 70]], dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8a857e50-ec20-4819-8505-a139dec427af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Targets (apples, oranges)\n",
    "target = np.array([[56, 70],\n",
    "                    [81, 101],\n",
    "                    [119, 133],\n",
    "                    [22, 37],\n",
    "                    [103, 119]], dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "02400a60-67ab-4f74-bac1-5449862beb7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 73.,  67.,  43.],\n",
      "        [ 91.,  88.,  64.],\n",
      "        [ 87., 134.,  58.],\n",
      "        [102.,  43.,  37.],\n",
      "        [ 69.,  96.,  70.]]) \n",
      "\n",
      "tensor([[ 56.,  70.],\n",
      "        [ 81., 101.],\n",
      "        [119., 133.],\n",
      "        [ 22.,  37.],\n",
      "        [103., 119.]])\n"
     ]
    }
   ],
   "source": [
    "#Convert input and target to tensors\n",
    "inputs = torch.from_numpy(inputs)\n",
    "target = torch.from_numpy(target)\n",
    "\n",
    "print(inputs,\"\\n\")\n",
    "print(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f558aaa1-b134-4c2a-a9bc-61fcd043c84c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.4749, -0.2452,  1.3185],\n",
      "        [-0.8625,  0.4079, -0.9293]], requires_grad=True)\n",
      "tensor([ 0.6216, -0.3526], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# weights and biases\n",
    "w = torch.randn(2,3 , requires_grad=True)\n",
    "b = torch.randn(2, requires_grad=True)\n",
    "\n",
    "print(w)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f2adf3b5-60f3-4c38-9f2c-525b61d2223a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the model\n",
    "\n",
    "def model(x):\n",
    "  return x @ w.t() + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "59d695ac-4604-47fc-8e35-77d3ded559fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  75.5578,  -75.9471],\n",
      "        [ 106.6455, -102.4214],\n",
      "        [  85.5568,  -74.6337],\n",
      "        [  87.3037, -105.1736],\n",
      "        [ 102.1468,  -85.7585]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# prediction\n",
    "preds = model(inputs)\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "38d06c17-a237-4d99-917d-351937ee67bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 56.,  70.],\n",
      "        [ 81., 101.],\n",
      "        [119., 133.],\n",
      "        [ 22.,  37.],\n",
      "        [103., 119.]])\n"
     ]
    }
   ],
   "source": [
    "#actual\n",
    "print(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "90ca1cea-2d06-4342-a076-230b9f5aa034",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function MSE\n",
    "def MSE(actual, target):\n",
    "  diff = actual - target\n",
    "  return torch.sum(diff * diff) / diff.numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "952cb2a9-022d-4e23-95a4-298e48071a09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(17435.5898, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# error\n",
    "loss = MSE(target, preds)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c354298e-8218-4432-adb7-4f7f48a46f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute gradients\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "18c64a49-2041-4194-8ad5-ba6a04c39cfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.4749, -0.2452,  1.3185],\n",
      "        [-0.8625,  0.4079, -0.9293]], requires_grad=True) \n",
      "\n",
      "tensor([[  1490.8020,    362.3886,    579.8210],\n",
      "        [-15171.9336, -16254.5479, -10186.1934]])\n"
     ]
    }
   ],
   "source": [
    "print(w, \"\\n\")\n",
    "print(w.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "05111d1a-fae3-453b-adeb-0a40570c891c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.6216, -0.3526], requires_grad=True) \n",
      "\n",
      "tensor([  15.2421, -180.7869])\n"
     ]
    }
   ],
   "source": [
    "print(b, \"\\n\")\n",
    "print(b.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4dc8fbab-ae9a-4264-94a5-3011016162de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "tensor([0., 0.])\n"
     ]
    }
   ],
   "source": [
    "#reset grad\n",
    "w.grad.zero_()\n",
    "b.grad.zero_()\n",
    "\n",
    "print(w.grad)\n",
    "print(b.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6f9da81e-f5c1-452b-8ae4-4607ec27f279",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  75.5578,  -75.9471],\n",
      "        [ 106.6455, -102.4214],\n",
      "        [  85.5568,  -74.6337],\n",
      "        [  87.3037, -105.1736],\n",
      "        [ 102.1468,  -85.7585]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# adjust params\n",
    "\n",
    "preds = model(inputs)\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4e278058-1dad-44e8-bd0a-eed305275164",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(17435.5898, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# loss\n",
    "loss = MSE(target, preds)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1b7ca54e-23f5-4b15-8645-991ea92dd065",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  1490.8020,    362.3886,    579.8210],\n",
      "        [-15171.9336, -16254.5479, -10186.1934]]) \n",
      "\n",
      "tensor([  15.2421, -180.7869])\n"
     ]
    }
   ],
   "source": [
    "loss.backward()\n",
    "\n",
    "print(w.grad, \"\\n\")\n",
    "print(b.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e692395e-83af-4134-937b-acc28b4f81ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "  # adjust weight & reset grad\n",
    "with torch.no_grad():\n",
    "    w -= w.grad * 1e-5\n",
    "    b -= b.grad * 1e-5\n",
    "    w.grad.zero_()\n",
    "    b.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "110bb275-42c9-4879-ae3b-eaddf5ec4d91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.4600, -0.2488,  1.3127],\n",
      "        [-0.7108,  0.5704, -0.8274]], requires_grad=True)\n",
      "tensor([ 0.6215, -0.3508], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(w)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "26865429-f46b-428c-a0f6-ab72100eb0da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(11964.2363, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# calculate again\n",
    "preds = model(inputs)\n",
    "loss = MSE(target, preds)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "83306110-7731-4635-83c6-7198cca70c8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs(0/100) & Loss 11964.236328125\n",
      "Epochs(1/100) & Loss 8274.884765625\n",
      "Epochs(2/100) & Loss 5786.42578125\n",
      "Epochs(3/100) & Loss 4107.259765625\n",
      "Epochs(4/100) & Loss 2973.490966796875\n",
      "Epochs(5/100) & Loss 2207.2861328125\n",
      "Epochs(6/100) & Loss 1688.802490234375\n",
      "Epochs(7/100) & Loss 1337.2821044921875\n",
      "Epochs(8/100) & Loss 1098.30078125\n",
      "Epochs(9/100) & Loss 935.1842651367188\n",
      "Epochs(10/100) & Loss 823.2176513671875\n",
      "Epochs(11/100) & Loss 745.744384765625\n",
      "Epochs(12/100) & Loss 691.5411376953125\n",
      "Epochs(13/100) & Loss 653.0432739257812\n",
      "Epochs(14/100) & Loss 625.1532592773438\n",
      "Epochs(15/100) & Loss 604.4356689453125\n",
      "Epochs(16/100) & Loss 588.5748291015625\n",
      "Epochs(17/100) & Loss 576.0101928710938\n",
      "Epochs(18/100) & Loss 565.689697265625\n",
      "Epochs(19/100) & Loss 556.9041748046875\n",
      "Epochs(20/100) & Loss 549.17529296875\n",
      "Epochs(21/100) & Loss 542.1806030273438\n",
      "Epochs(22/100) & Loss 535.7025146484375\n",
      "Epochs(23/100) & Loss 529.59423828125\n",
      "Epochs(24/100) & Loss 523.7559814453125\n",
      "Epochs(25/100) & Loss 518.12109375\n",
      "Epochs(26/100) & Loss 512.6438598632812\n",
      "Epochs(27/100) & Loss 507.29315185546875\n",
      "Epochs(28/100) & Loss 502.04803466796875\n",
      "Epochs(29/100) & Loss 496.8941345214844\n",
      "Epochs(30/100) & Loss 491.82135009765625\n",
      "Epochs(31/100) & Loss 486.822509765625\n",
      "Epochs(32/100) & Loss 481.89276123046875\n",
      "Epochs(33/100) & Loss 477.02874755859375\n",
      "Epochs(34/100) & Loss 472.22760009765625\n",
      "Epochs(35/100) & Loss 467.48724365234375\n",
      "Epochs(36/100) & Loss 462.80633544921875\n",
      "Epochs(37/100) & Loss 458.18316650390625\n",
      "Epochs(38/100) & Loss 453.61724853515625\n",
      "Epochs(39/100) & Loss 449.10687255859375\n",
      "Epochs(40/100) & Loss 444.65179443359375\n",
      "Epochs(41/100) & Loss 440.2508850097656\n",
      "Epochs(42/100) & Loss 435.9034118652344\n",
      "Epochs(43/100) & Loss 431.60882568359375\n",
      "Epochs(44/100) & Loss 427.36614990234375\n",
      "Epochs(45/100) & Loss 423.1749572753906\n",
      "Epochs(46/100) & Loss 419.03436279296875\n",
      "Epochs(47/100) & Loss 414.94390869140625\n",
      "Epochs(48/100) & Loss 410.9029846191406\n",
      "Epochs(49/100) & Loss 406.9106140136719\n",
      "Epochs(50/100) & Loss 402.966796875\n",
      "Epochs(51/100) & Loss 399.0703125\n",
      "Epochs(52/100) & Loss 395.220947265625\n",
      "Epochs(53/100) & Loss 391.41778564453125\n",
      "Epochs(54/100) & Loss 387.6607666015625\n",
      "Epochs(55/100) & Loss 383.94879150390625\n",
      "Epochs(56/100) & Loss 380.28155517578125\n",
      "Epochs(57/100) & Loss 376.6583251953125\n",
      "Epochs(58/100) & Loss 373.07879638671875\n",
      "Epochs(59/100) & Loss 369.54229736328125\n",
      "Epochs(60/100) & Loss 366.0481262207031\n",
      "Epochs(61/100) & Loss 362.5960693359375\n",
      "Epochs(62/100) & Loss 359.1851806640625\n",
      "Epochs(63/100) & Loss 355.8154296875\n",
      "Epochs(64/100) & Loss 352.4859924316406\n",
      "Epochs(65/100) & Loss 349.1964416503906\n",
      "Epochs(66/100) & Loss 345.9462585449219\n",
      "Epochs(67/100) & Loss 342.7350158691406\n",
      "Epochs(68/100) & Loss 339.5620422363281\n",
      "Epochs(69/100) & Loss 336.4271545410156\n",
      "Epochs(70/100) & Loss 333.32958984375\n",
      "Epochs(71/100) & Loss 330.2691955566406\n",
      "Epochs(72/100) & Loss 327.24517822265625\n",
      "Epochs(73/100) & Loss 324.25714111328125\n",
      "Epochs(74/100) & Loss 321.3048400878906\n",
      "Epochs(75/100) & Loss 318.3876037597656\n",
      "Epochs(76/100) & Loss 315.50531005859375\n",
      "Epochs(77/100) & Loss 312.6571350097656\n",
      "Epochs(78/100) & Loss 309.84271240234375\n",
      "Epochs(79/100) & Loss 307.0618896484375\n",
      "Epochs(80/100) & Loss 304.3140869140625\n",
      "Epochs(81/100) & Loss 301.5988464355469\n",
      "Epochs(82/100) & Loss 298.9157409667969\n",
      "Epochs(83/100) & Loss 296.2643127441406\n",
      "Epochs(84/100) & Loss 293.6445617675781\n",
      "Epochs(85/100) & Loss 291.0556640625\n",
      "Epochs(86/100) & Loss 288.4974060058594\n",
      "Epochs(87/100) & Loss 285.96942138671875\n",
      "Epochs(88/100) & Loss 283.47125244140625\n",
      "Epochs(89/100) & Loss 281.00250244140625\n",
      "Epochs(90/100) & Loss 278.5628356933594\n",
      "Epochs(91/100) & Loss 276.1520690917969\n",
      "Epochs(92/100) & Loss 273.7696838378906\n",
      "Epochs(93/100) & Loss 271.41534423828125\n",
      "Epochs(94/100) & Loss 269.0885314941406\n",
      "Epochs(95/100) & Loss 266.7891845703125\n",
      "Epochs(96/100) & Loss 264.51678466796875\n",
      "Epochs(97/100) & Loss 262.2709655761719\n",
      "Epochs(98/100) & Loss 260.0516357421875\n",
      "Epochs(99/100) & Loss 257.8582763671875\n",
      "Epochs(100/100) & Loss 255.69052124023438\n",
      "Epochs(101/100) & Loss 253.54818725585938\n",
      "Epochs(102/100) & Loss 251.4308319091797\n",
      "Epochs(103/100) & Loss 249.3383026123047\n",
      "Epochs(104/100) & Loss 247.2700958251953\n",
      "Epochs(105/100) & Loss 245.22598266601562\n",
      "Epochs(106/100) & Loss 243.2057647705078\n",
      "Epochs(107/100) & Loss 241.20901489257812\n",
      "Epochs(108/100) & Loss 239.2354278564453\n",
      "Epochs(109/100) & Loss 237.284912109375\n",
      "Epochs(110/100) & Loss 235.35690307617188\n",
      "Epochs(111/100) & Loss 233.45138549804688\n",
      "Epochs(112/100) & Loss 231.56784057617188\n",
      "Epochs(113/100) & Loss 229.70614624023438\n",
      "Epochs(114/100) & Loss 227.86605834960938\n",
      "Epochs(115/100) & Loss 226.0471649169922\n",
      "Epochs(116/100) & Loss 224.2491455078125\n",
      "Epochs(117/100) & Loss 222.4721221923828\n",
      "Epochs(118/100) & Loss 220.71554565429688\n",
      "Epochs(119/100) & Loss 218.9790496826172\n",
      "Epochs(120/100) & Loss 217.2626495361328\n",
      "Epochs(121/100) & Loss 215.5658721923828\n",
      "Epochs(122/100) & Loss 213.88864135742188\n",
      "Epochs(123/100) & Loss 212.2307586669922\n",
      "Epochs(124/100) & Loss 210.59170532226562\n",
      "Epochs(125/100) & Loss 208.97146606445312\n",
      "Epochs(126/100) & Loss 207.3698272705078\n",
      "Epochs(127/100) & Loss 205.78646850585938\n",
      "Epochs(128/100) & Loss 204.22109985351562\n",
      "Epochs(129/100) & Loss 202.6737060546875\n",
      "Epochs(130/100) & Loss 201.14385986328125\n",
      "Epochs(131/100) & Loss 199.63140869140625\n",
      "Epochs(132/100) & Loss 198.13623046875\n",
      "Epochs(133/100) & Loss 196.657958984375\n",
      "Epochs(134/100) & Loss 195.19647216796875\n",
      "Epochs(135/100) & Loss 193.7516326904297\n",
      "Epochs(136/100) & Loss 192.3229522705078\n",
      "Epochs(137/100) & Loss 190.91062927246094\n",
      "Epochs(138/100) & Loss 189.51406860351562\n",
      "Epochs(139/100) & Loss 188.13336181640625\n",
      "Epochs(140/100) & Loss 186.768310546875\n",
      "Epochs(141/100) & Loss 185.41848754882812\n",
      "Epochs(142/100) & Loss 184.08383178710938\n",
      "Epochs(143/100) & Loss 182.76431274414062\n",
      "Epochs(144/100) & Loss 181.45944213867188\n",
      "Epochs(145/100) & Loss 180.16912841796875\n",
      "Epochs(146/100) & Loss 178.89352416992188\n",
      "Epochs(147/100) & Loss 177.63192749023438\n",
      "Epochs(148/100) & Loss 176.38450622558594\n",
      "Epochs(149/100) & Loss 175.15101623535156\n",
      "Epochs(150/100) & Loss 173.93118286132812\n",
      "Epochs(151/100) & Loss 172.7250213623047\n",
      "Epochs(152/100) & Loss 171.53216552734375\n",
      "Epochs(153/100) & Loss 170.35256958007812\n",
      "Epochs(154/100) & Loss 169.18601989746094\n",
      "Epochs(155/100) & Loss 168.0323486328125\n",
      "Epochs(156/100) & Loss 166.89151000976562\n",
      "Epochs(157/100) & Loss 165.76318359375\n",
      "Epochs(158/100) & Loss 164.6474151611328\n",
      "Epochs(159/100) & Loss 163.5437774658203\n",
      "Epochs(160/100) & Loss 162.45228576660156\n",
      "Epochs(161/100) & Loss 161.37283325195312\n",
      "Epochs(162/100) & Loss 160.30514526367188\n",
      "Epochs(163/100) & Loss 159.24917602539062\n",
      "Epochs(164/100) & Loss 158.20477294921875\n",
      "Epochs(165/100) & Loss 157.1718292236328\n",
      "Epochs(166/100) & Loss 156.15000915527344\n",
      "Epochs(167/100) & Loss 155.13943481445312\n",
      "Epochs(168/100) & Loss 154.13978576660156\n",
      "Epochs(169/100) & Loss 153.15081787109375\n",
      "Epochs(170/100) & Loss 152.17279052734375\n",
      "Epochs(171/100) & Loss 151.20529174804688\n",
      "Epochs(172/100) & Loss 150.2481231689453\n",
      "Epochs(173/100) & Loss 149.30148315429688\n",
      "Epochs(174/100) & Loss 148.36474609375\n",
      "Epochs(175/100) & Loss 147.43826293945312\n",
      "Epochs(176/100) & Loss 146.5218048095703\n",
      "Epochs(177/100) & Loss 145.61500549316406\n",
      "Epochs(178/100) & Loss 144.71798706054688\n",
      "Epochs(179/100) & Loss 143.83059692382812\n",
      "Epochs(180/100) & Loss 142.95252990722656\n",
      "Epochs(181/100) & Loss 142.08389282226562\n",
      "Epochs(182/100) & Loss 141.2244873046875\n",
      "Epochs(183/100) & Loss 140.37417602539062\n",
      "Epochs(184/100) & Loss 139.53286743164062\n",
      "Epochs(185/100) & Loss 138.70054626464844\n",
      "Epochs(186/100) & Loss 137.87696838378906\n",
      "Epochs(187/100) & Loss 137.06195068359375\n",
      "Epochs(188/100) & Loss 136.2556915283203\n",
      "Epochs(189/100) & Loss 135.45779418945312\n",
      "Epochs(190/100) & Loss 134.66824340820312\n",
      "Epochs(191/100) & Loss 133.88717651367188\n",
      "Epochs(192/100) & Loss 133.1140899658203\n",
      "Epochs(193/100) & Loss 132.34902954101562\n",
      "Epochs(194/100) & Loss 131.59197998046875\n",
      "Epochs(195/100) & Loss 130.84280395507812\n",
      "Epochs(196/100) & Loss 130.10128784179688\n",
      "Epochs(197/100) & Loss 129.36758422851562\n",
      "Epochs(198/100) & Loss 128.6414031982422\n",
      "Epochs(199/100) & Loss 127.92279052734375\n",
      "Epochs(200/100) & Loss 127.21148681640625\n",
      "Epochs(201/100) & Loss 126.507568359375\n",
      "Epochs(202/100) & Loss 125.810791015625\n",
      "Epochs(203/100) & Loss 125.12110900878906\n",
      "Epochs(204/100) & Loss 124.43864440917969\n",
      "Epochs(205/100) & Loss 123.76300048828125\n",
      "Epochs(206/100) & Loss 123.09422302246094\n",
      "Epochs(207/100) & Loss 122.43229675292969\n",
      "Epochs(208/100) & Loss 121.77699279785156\n",
      "Epochs(209/100) & Loss 121.12843322753906\n",
      "Epochs(210/100) & Loss 120.48634338378906\n",
      "Epochs(211/100) & Loss 119.85064697265625\n",
      "Epochs(212/100) & Loss 119.22139739990234\n",
      "Epochs(213/100) & Loss 118.59857177734375\n",
      "Epochs(214/100) & Loss 117.9818344116211\n",
      "Epochs(215/100) & Loss 117.3712158203125\n",
      "Epochs(216/100) & Loss 116.76680755615234\n",
      "Epochs(217/100) & Loss 116.16837310791016\n",
      "Epochs(218/100) & Loss 115.57575988769531\n",
      "Epochs(219/100) & Loss 114.98915100097656\n",
      "Epochs(220/100) & Loss 114.40834045410156\n",
      "Epochs(221/100) & Loss 113.83317565917969\n",
      "Epochs(222/100) & Loss 113.26365661621094\n",
      "Epochs(223/100) & Loss 112.69979095458984\n",
      "Epochs(224/100) & Loss 112.14137268066406\n",
      "Epochs(225/100) & Loss 111.58846282958984\n",
      "Epochs(226/100) & Loss 111.04093933105469\n",
      "Epochs(227/100) & Loss 110.4986801147461\n",
      "Epochs(228/100) & Loss 109.96173095703125\n",
      "Epochs(229/100) & Loss 109.42984771728516\n",
      "Epochs(230/100) & Loss 108.90321350097656\n",
      "Epochs(231/100) & Loss 108.38160705566406\n",
      "Epochs(232/100) & Loss 107.86492919921875\n",
      "Epochs(233/100) & Loss 107.3533706665039\n",
      "Epochs(234/100) & Loss 106.8465805053711\n",
      "Epochs(235/100) & Loss 106.34461975097656\n",
      "Epochs(236/100) & Loss 105.8475112915039\n",
      "Epochs(237/100) & Loss 105.35502624511719\n",
      "Epochs(238/100) & Loss 104.86723327636719\n",
      "Epochs(239/100) & Loss 104.3841323852539\n",
      "Epochs(240/100) & Loss 103.90544128417969\n",
      "Epochs(241/100) & Loss 103.43122863769531\n",
      "Epochs(242/100) & Loss 102.96146392822266\n",
      "Epochs(243/100) & Loss 102.49625396728516\n",
      "Epochs(244/100) & Loss 102.03517150878906\n",
      "Epochs(245/100) & Loss 101.57838439941406\n",
      "Epochs(246/100) & Loss 101.12590789794922\n",
      "Epochs(247/100) & Loss 100.67759704589844\n",
      "Epochs(248/100) & Loss 100.23338317871094\n",
      "Epochs(249/100) & Loss 99.7933120727539\n",
      "Epochs(250/100) & Loss 99.35710144042969\n",
      "Epochs(251/100) & Loss 98.92510223388672\n",
      "Epochs(252/100) & Loss 98.49691772460938\n",
      "Epochs(253/100) & Loss 98.07264709472656\n",
      "Epochs(254/100) & Loss 97.6521987915039\n",
      "Epochs(255/100) & Loss 97.23545837402344\n",
      "Epochs(256/100) & Loss 96.82267761230469\n",
      "Epochs(257/100) & Loss 96.41341400146484\n",
      "Epochs(258/100) & Loss 96.00787353515625\n",
      "Epochs(259/100) & Loss 95.60591125488281\n",
      "Epochs(260/100) & Loss 95.20758056640625\n",
      "Epochs(261/100) & Loss 94.81272888183594\n",
      "Epochs(262/100) & Loss 94.42144775390625\n",
      "Epochs(263/100) & Loss 94.03365325927734\n",
      "Epochs(264/100) & Loss 93.64918518066406\n",
      "Epochs(265/100) & Loss 93.2680435180664\n",
      "Epochs(266/100) & Loss 92.89031219482422\n",
      "Epochs(267/100) & Loss 92.51575469970703\n",
      "Epochs(268/100) & Loss 92.14457702636719\n",
      "Epochs(269/100) & Loss 91.77654266357422\n",
      "Epochs(270/100) & Loss 91.4117660522461\n",
      "Epochs(271/100) & Loss 91.05001831054688\n",
      "Epochs(272/100) & Loss 90.69145202636719\n",
      "Epochs(273/100) & Loss 90.33592224121094\n",
      "Epochs(274/100) & Loss 89.98343658447266\n",
      "Epochs(275/100) & Loss 89.6339340209961\n",
      "Epochs(276/100) & Loss 89.28728485107422\n",
      "Epochs(277/100) & Loss 88.94374084472656\n",
      "Epochs(278/100) & Loss 88.60301208496094\n",
      "Epochs(279/100) & Loss 88.26509094238281\n",
      "Epochs(280/100) & Loss 87.93006896972656\n",
      "Epochs(281/100) & Loss 87.59771728515625\n",
      "Epochs(282/100) & Loss 87.26821899414062\n",
      "Epochs(283/100) & Loss 86.94137573242188\n",
      "Epochs(284/100) & Loss 86.6173324584961\n",
      "Epochs(285/100) & Loss 86.29588317871094\n",
      "Epochs(286/100) & Loss 85.9769515991211\n",
      "Epochs(287/100) & Loss 85.66082763671875\n",
      "Epochs(288/100) & Loss 85.34716033935547\n",
      "Epochs(289/100) & Loss 85.03607177734375\n",
      "Epochs(290/100) & Loss 84.72740173339844\n",
      "Epochs(291/100) & Loss 84.42138671875\n",
      "Epochs(292/100) & Loss 84.11775207519531\n",
      "Epochs(293/100) & Loss 83.81641387939453\n",
      "Epochs(294/100) & Loss 83.51762390136719\n",
      "Epochs(295/100) & Loss 83.22113037109375\n",
      "Epochs(296/100) & Loss 82.92703247070312\n",
      "Epochs(297/100) & Loss 82.63507080078125\n",
      "Epochs(298/100) & Loss 82.34567260742188\n",
      "Epochs(299/100) & Loss 82.05836486816406\n",
      "Epochs(300/100) & Loss 81.77336883544922\n",
      "Epochs(301/100) & Loss 81.49055480957031\n",
      "Epochs(302/100) & Loss 81.20985412597656\n",
      "Epochs(303/100) & Loss 80.93134307861328\n",
      "Epochs(304/100) & Loss 80.65499114990234\n",
      "Epochs(305/100) & Loss 80.38082885742188\n",
      "Epochs(306/100) & Loss 80.10867309570312\n",
      "Epochs(307/100) & Loss 79.83861541748047\n",
      "Epochs(308/100) & Loss 79.57050323486328\n",
      "Epochs(309/100) & Loss 79.30445861816406\n",
      "Epochs(310/100) & Loss 79.04044342041016\n",
      "Epochs(311/100) & Loss 78.77833557128906\n",
      "Epochs(312/100) & Loss 78.51826477050781\n",
      "Epochs(313/100) & Loss 78.26006317138672\n",
      "Epochs(314/100) & Loss 78.00372314453125\n",
      "Epochs(315/100) & Loss 77.74928283691406\n",
      "Epochs(316/100) & Loss 77.49681091308594\n",
      "Epochs(317/100) & Loss 77.24610900878906\n",
      "Epochs(318/100) & Loss 76.99718475341797\n",
      "Epochs(319/100) & Loss 76.75012969970703\n",
      "Epochs(320/100) & Loss 76.50481414794922\n",
      "Epochs(321/100) & Loss 76.26124572753906\n",
      "Epochs(322/100) & Loss 76.01945495605469\n",
      "Epochs(323/100) & Loss 75.77940368652344\n",
      "Epochs(324/100) & Loss 75.54106903076172\n",
      "Epochs(325/100) & Loss 75.30432891845703\n",
      "Epochs(326/100) & Loss 75.06917572021484\n",
      "Epochs(327/100) & Loss 74.83589172363281\n",
      "Epochs(328/100) & Loss 74.60403442382812\n",
      "Epochs(329/100) & Loss 74.37384033203125\n",
      "Epochs(330/100) & Loss 74.14527893066406\n",
      "Epochs(331/100) & Loss 73.91829681396484\n",
      "Epochs(332/100) & Loss 73.6928939819336\n",
      "Epochs(333/100) & Loss 73.46890258789062\n",
      "Epochs(334/100) & Loss 73.24657440185547\n",
      "Epochs(335/100) & Loss 73.02568817138672\n",
      "Epochs(336/100) & Loss 72.80628204345703\n",
      "Epochs(337/100) & Loss 72.58833312988281\n",
      "Epochs(338/100) & Loss 72.37191009521484\n",
      "Epochs(339/100) & Loss 72.15684509277344\n",
      "Epochs(340/100) & Loss 71.94322967529297\n",
      "Epochs(341/100) & Loss 71.7310791015625\n",
      "Epochs(342/100) & Loss 71.52021789550781\n",
      "Epochs(343/100) & Loss 71.3108139038086\n",
      "Epochs(344/100) & Loss 71.1027603149414\n",
      "Epochs(345/100) & Loss 70.89607238769531\n",
      "Epochs(346/100) & Loss 70.69063568115234\n",
      "Epochs(347/100) & Loss 70.48658752441406\n",
      "Epochs(348/100) & Loss 70.28373718261719\n",
      "Epochs(349/100) & Loss 70.08233642578125\n",
      "Epochs(350/100) & Loss 69.88209533691406\n",
      "Epochs(351/100) & Loss 69.68319702148438\n",
      "Epochs(352/100) & Loss 69.4854736328125\n",
      "Epochs(353/100) & Loss 69.2890853881836\n",
      "Epochs(354/100) & Loss 69.09380340576172\n",
      "Epochs(355/100) & Loss 68.89979553222656\n",
      "Epochs(356/100) & Loss 68.70698547363281\n",
      "Epochs(357/100) & Loss 68.5152816772461\n",
      "Epochs(358/100) & Loss 68.32486724853516\n",
      "Epochs(359/100) & Loss 68.13548278808594\n",
      "Epochs(360/100) & Loss 67.9474105834961\n",
      "Epochs(361/100) & Loss 67.76036071777344\n",
      "Epochs(362/100) & Loss 67.57444763183594\n",
      "Epochs(363/100) & Loss 67.38965606689453\n",
      "Epochs(364/100) & Loss 67.20594787597656\n",
      "Epochs(365/100) & Loss 67.02336120605469\n",
      "Epochs(366/100) & Loss 66.84181213378906\n",
      "Epochs(367/100) & Loss 66.66131591796875\n",
      "Epochs(368/100) & Loss 66.48187255859375\n",
      "Epochs(369/100) & Loss 66.30347442626953\n",
      "Epochs(370/100) & Loss 66.12614440917969\n",
      "Epochs(371/100) & Loss 65.94979095458984\n",
      "Epochs(372/100) & Loss 65.7745132446289\n",
      "Epochs(373/100) & Loss 65.60020446777344\n",
      "Epochs(374/100) & Loss 65.42686462402344\n",
      "Epochs(375/100) & Loss 65.25447082519531\n",
      "Epochs(376/100) & Loss 65.08314514160156\n",
      "Epochs(377/100) & Loss 64.91270446777344\n",
      "Epochs(378/100) & Loss 64.74320220947266\n",
      "Epochs(379/100) & Loss 64.57466125488281\n",
      "Epochs(380/100) & Loss 64.4070816040039\n",
      "Epochs(381/100) & Loss 64.2403335571289\n",
      "Epochs(382/100) & Loss 64.07449340820312\n",
      "Epochs(383/100) & Loss 63.90977096557617\n",
      "Epochs(384/100) & Loss 63.7457275390625\n",
      "Epochs(385/100) & Loss 63.582618713378906\n",
      "Epochs(386/100) & Loss 63.420387268066406\n",
      "Epochs(387/100) & Loss 63.259010314941406\n",
      "Epochs(388/100) & Loss 63.09851837158203\n",
      "Epochs(389/100) & Loss 62.93888473510742\n",
      "Epochs(390/100) & Loss 62.7800407409668\n",
      "Epochs(391/100) & Loss 62.6220703125\n",
      "Epochs(392/100) & Loss 62.464866638183594\n",
      "Epochs(393/100) & Loss 62.30852127075195\n",
      "Epochs(394/100) & Loss 62.15300750732422\n",
      "Epochs(395/100) & Loss 61.998260498046875\n",
      "Epochs(396/100) & Loss 61.84431838989258\n",
      "Epochs(397/100) & Loss 61.69118118286133\n",
      "Epochs(398/100) & Loss 61.538726806640625\n",
      "Epochs(399/100) & Loss 61.38710403442383\n"
     ]
    }
   ],
   "source": [
    "# Training for multiple epochs\n",
    "for i in range(400):\n",
    "  preds = model(inputs)\n",
    "  loss = MSE(target, preds)\n",
    "  loss.backward()\n",
    "\n",
    "  with torch.no_grad():\n",
    "     w -= w.grad * 1e-5 # learning rate\n",
    "     b -= b.grad * 1e-5\n",
    "     w.grad.zero_()\n",
    "     b.grad.zero_()\n",
    "  print(f\"Epochs({i}/{100}) & Loss {loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c5518ab3-f181-420b-8991-b76e14c44d8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(61.2362, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "preds = model(inputs)\n",
    "loss = MSE(target, preds)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "100dd636-e7f2-422e-a36e-2f4b4864565e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.825359046181853"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from math import sqrt\n",
    "sqrt(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3c8b4a27-7934-4b59-8cf5-b79fe0cfaf0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 57.6522,  71.0231],\n",
       "        [ 86.4198,  94.0661],\n",
       "        [108.3306, 146.8293],\n",
       "        [ 23.7079,  40.7828],\n",
       "        [107.8376, 105.3831]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5b4335ab-6a24-4410-b382-eba8619fff14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 56.,  70.],\n",
       "        [ 81., 101.],\n",
       "        [119., 133.],\n",
       "        [ 22.,  37.],\n",
       "        [103., 119.]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c2760a-6953-4501-bf38-a1b850e954e0",
   "metadata": {},
   "source": [
    "## Neural Network using Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e05a5c5f-de29-4585-a28e-15d5644d5f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor, Lambda, Compose\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "dfae0aaa-0de7-4396-9db3-3b1de9224713",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to data\\FashionMNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 26.4M/26.4M [00:13<00:00, 1.99MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\FashionMNIST\\raw\\train-images-idx3-ubyte.gz to data\\FashionMNIST\\raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to data\\FashionMNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 29.5k/29.5k [00:00<00:00, 180kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\FashionMNIST\\raw\\train-labels-idx1-ubyte.gz to data\\FashionMNIST\\raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to data\\FashionMNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 4.42M/4.42M [00:02<00:00, 2.02MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\FashionMNIST\\raw\\t10k-images-idx3-ubyte.gz to data\\FashionMNIST\\raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to data\\FashionMNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████| 5.15k/5.15k [00:00<?, ?B/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\FashionMNIST\\raw\\t10k-labels-idx1-ubyte.gz to data\\FashionMNIST\\raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Download training data from open datasets.\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "# Download test data from open datasets.\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "31463397-4912-4f9e-b5dd-631bed19c422",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torchvision.datasets.mnist.FashionMNIST"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f75fd7d8-159b-4a9e-be4e-320988cd1579",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X [N, C, H, W]:  torch.Size([64, 1, 28, 28])\n",
      "Shape of y:  torch.Size([64]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "\n",
    "# Create data loaders.\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "for X, y in test_dataloader:\n",
    "    print(\"Shape of X [N, C, H, W]: \", X.shape)\n",
    "    print(\"Shape of y: \", y.shape, y.dtype)\n",
    "    # print(X)\n",
    "    # print(y)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "428f940e-c853-41ea-9b42-fa1b7e47a99e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "# Get cpu or gpu device for training.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e3bfdb16-b614-4c98-8d2c-cf1db058a7ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Define model\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "521baa23-e3f0-49b3-b1ed-3731de3c4508",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5b215d58-1306-474f-b495-01ad6d8d1b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "060f7ab3-af90-4846-b569-6e2698c66426",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7ea11893-e3e3-470c-b32b-50c55e332f58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.302841  [    0/60000]\n",
      "loss: 2.291980  [ 6400/60000]\n",
      "loss: 2.273289  [12800/60000]\n",
      "loss: 2.268360  [19200/60000]\n",
      "loss: 2.252009  [25600/60000]\n",
      "loss: 2.221667  [32000/60000]\n",
      "loss: 2.238112  [38400/60000]\n",
      "loss: 2.196827  [44800/60000]\n",
      "loss: 2.196028  [51200/60000]\n",
      "loss: 2.160621  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 38.8%, Avg loss: 2.156242 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 2.165525  [    0/60000]\n",
      "loss: 2.155755  [ 6400/60000]\n",
      "loss: 2.100467  [12800/60000]\n",
      "loss: 2.113699  [19200/60000]\n",
      "loss: 2.060928  [25600/60000]\n",
      "loss: 2.007727  [32000/60000]\n",
      "loss: 2.034311  [38400/60000]\n",
      "loss: 1.952234  [44800/60000]\n",
      "loss: 1.957839  [51200/60000]\n",
      "loss: 1.878014  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 59.0%, Avg loss: 1.882395 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1.915700  [    0/60000]\n",
      "loss: 1.886109  [ 6400/60000]\n",
      "loss: 1.770703  [12800/60000]\n",
      "loss: 1.802860  [19200/60000]\n",
      "loss: 1.694619  [25600/60000]\n",
      "loss: 1.652606  [32000/60000]\n",
      "loss: 1.663353  [38400/60000]\n",
      "loss: 1.567898  [44800/60000]\n",
      "loss: 1.589405  [51200/60000]\n",
      "loss: 1.477087  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 61.1%, Avg loss: 1.506790 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 1.569911  [    0/60000]\n",
      "loss: 1.541022  [ 6400/60000]\n",
      "loss: 1.392811  [12800/60000]\n",
      "loss: 1.458844  [19200/60000]\n",
      "loss: 1.339245  [25600/60000]\n",
      "loss: 1.340258  [32000/60000]\n",
      "loss: 1.345495  [38400/60000]\n",
      "loss: 1.273079  [44800/60000]\n",
      "loss: 1.308511  [51200/60000]\n",
      "loss: 1.205715  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 63.1%, Avg loss: 1.240602 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 1.312176  [    0/60000]\n",
      "loss: 1.301210  [ 6400/60000]\n",
      "loss: 1.136282  [12800/60000]\n",
      "loss: 1.240186  [19200/60000]\n",
      "loss: 1.109908  [25600/60000]\n",
      "loss: 1.140709  [32000/60000]\n",
      "loss: 1.157981  [38400/60000]\n",
      "loss: 1.093126  [44800/60000]\n",
      "loss: 1.136135  [51200/60000]\n",
      "loss: 1.051247  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 64.6%, Avg loss: 1.078111 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17134c66-4fae-4a89-818c-d49a06e56bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save model\n",
    "torch.save(model.state_dict(), \"model.pth\")\n",
    "print(\"Saved PyTorch Model State to model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07055508-7807-4ef2-a9fe-56946e6374da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load model\n",
    "model = NeuralNetwork()\n",
    "model.load_state_dict(torch.load(\"model.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143a36f5-618e-4ac1-824a-6aa18bd7eca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Prediction\n",
    "\n",
    "classes = [\n",
    "    \"T-shirt/top\",\n",
    "    \"Trouser\",\n",
    "    \"Pullover\",\n",
    "    \"Dress\",\n",
    "    \"Coat\",\n",
    "    \"Sandal\",\n",
    "    \"Shirt\",\n",
    "    \"Sneaker\",\n",
    "    \"Bag\",\n",
    "    \"Ankle boot\",\n",
    "]\n",
    "\n",
    "model.eval()\n",
    "x, y = test_data[0][0], test_data[0][1]\n",
    "with torch.no_grad():\n",
    "    pred = model(x)\n",
    "    predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
    "    print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4351dd18-a941-469d-9f56-bb28370caba1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
